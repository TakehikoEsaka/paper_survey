{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ls\n",
    "・!でコマンド確認可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "27995       0       0       0       0       0       0       0       0       0   \n",
       "27996       0       0       0       0       0       0       0       0       0   \n",
       "27997       0       0       0       0       0       0       0       0       0   \n",
       "27998       0       0       0       0       0       0       0       0       0   \n",
       "27999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "27995       0  ...         0         0         0         0         0   \n",
       "27996       0  ...         0         0         0         0         0   \n",
       "27997       0  ...         0         0         0         0         0   \n",
       "27998       0  ...         0         0         0         0         0   \n",
       "27999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27995         0         0         0         0         0  \n",
       "27996         0         0         0         0         0  \n",
       "27997         0         0         0         0         0  \n",
       "27998         0         0         0         0         0  \n",
       "27999         0         0         0         0         0  \n",
       "\n",
       "[28000 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・画像はグレースケール\n",
    "・trainには学習用の答えlabel\n",
    "・testにはlabelなし？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# free some space\n",
    "del train \n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ノーマライゼーション：画素値を0-1に\n",
    "pythonのreshape(-1は？)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshapeで\n",
    "[データ数, height, width, color_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Split training and valdiation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainデータ：37800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some examples\n",
    "g = plt.imshow(X_train[1][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * 7* 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#計算①\n",
    "# 28 * 28\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "\n",
    "# 28 * 28* 32\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "# 28 * 28* 32\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# MaxPool2DのストライドデフォルトはNoneで，pool_sizeと等しくなる．\n",
    "\n",
    "# 14 * 14 * 32\n",
    "model.add(Dropout(0.25))\n",
    "# Dropout (重みを指定した割合だけ0にして無効にする．)\n",
    "#この場合，1/4をランダムに無効にする．アンサンブルして結果を良くする．\n",
    "\n",
    "#計算②\n",
    "# 14 * 14 * 32\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "\n",
    "# 14 * 14 * 64\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "\n",
    "# 14 * 14 * 64\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "# 7 * 7 * 64\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 7 * 7 * 64\n",
    "model.add(Flatten())\n",
    "\n",
    "# 3136\n",
    "# Denseはaffineと同じように，ノードを結ぶ働きをする．\n",
    "model.add(Dense(256, activation = \"relu\")) # 出力は256個のノード\n",
    "\n",
    "# 256\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 256\n",
    "model.add(Dense(10, activation = \"softmax\"))# 出力は10個のノード\n",
    "\n",
    "# 10\n",
    "# Denseは最後の層だけ使うのが普通．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#lr : 学習率\n",
    "# rho, epsilon : rmsiのパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "#softmaxは出力が10クラスの確率[0,0,0.8,0,0,0,0,0,0.2,0] = 足したら1\n",
    "# カテゴリカルクロスエントリピー ：ラベル[0,0,1,0,0,0,0,0,0,0] とエントロピー計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation i obtained an accuracy of 0.98114\n",
    "#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "#          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-54b73dab410d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                               , callbacks=[learning_rate_reduction])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelの構造保存\n",
    "json_string = model.to_json()\n",
    "open('digit_recognizer_model.json', 'w').write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重みの保存\n",
    "model.save_weights('digit_recognizer_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes \"FROM\" one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations \"FROM\" one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "\n",
    "#あるカラムだけ1で他のカラムは0な行列の表現。カテゴリー変数でよく使います。\n",
    "#古典的な統計の教科書では「ダミー変数」という言い方もします。\n",
    "#PandasのOneHotベクトルを作る関数get_dummiesはこれが由来です。\n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error見る．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelから行う方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル構造ファイルと重みから予測する方法\n",
    "モデル構造：digit_recognizer_model.json <br>\n",
    "重みファイル：digit_recognizer_weights.h5 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "model = model_from_json(open('digit_recognizer_model.json', 'r').read())\n",
    "\n",
    "#重みの読み込み\n",
    "model.load_weights('mnist_mlp_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test[0:100].shape)\n",
    "results = model.predict(test[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "[2 0 9 0 3 7 0 3 0 3 5 7 4 0 4 3 3 1 9 0 9 1 1 5 7 4 2 7 4 7 7 5 4 2 6 2 5\n",
      " 5 1 6 7 7 4 9 8 7 8 2 6 7 6 8 8 3 8 2 1 2 2 0 4 1 7 0 0 0 1 9 0 1 6 5 8 8\n",
      " 2 8 9 9 2 3 5 4 1 0 9 2 4 3 6 7 2 0 6 6 1 4 3 9 7 4]\n"
     ]
    }
   ],
   "source": [
    "# data_num * class_num\n",
    "print(results.shape)\n",
    "\n",
    "predicted = np.argmax(results, axis = 1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-Cam ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import keras\n",
    "import sys\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grad_Cam_plus_plus(input_model, layer_name, x, row, col):\n",
    "\n",
    "    model = input_model\n",
    "\n",
    "    # 前処理\n",
    "    #X = np.expand_dims(x, axis=0)\n",
    "    #X = X.astype('float32')\n",
    "    #preprocessed_input = X / 255.0\n",
    "\n",
    "    # 予測クラスの算出\n",
    "    #predictions = model.predict(preprocessed_input)\n",
    "    print(\"入力：\" + str(x.shape))\n",
    "    predictions = model.predict(x)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "\n",
    "    #  使用する重みの抽出、高階微分の計算\n",
    "    class_output = model.layers[-1].output\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = K.gradients(class_output, conv_output)[0]\n",
    "    #first_derivative：１階微分\n",
    "    first_derivative = K.exp(class_output)[0][class_idx] * grads\n",
    "    #second_derivative：２階微分\n",
    "    second_derivative = K.exp(class_output)[0][class_idx] * grads * grads\n",
    "    #third_derivative：３階微分\n",
    "    third_derivative = K.exp(class_output)[0][class_idx] * grads * grads * grads\n",
    "\n",
    "    #関数の定義\n",
    "    gradient_function = K.function([model.input], [conv_output, first_derivative, second_derivative, third_derivative])  # model.inputを入力すると、conv_outputとgradsを出力する関数\n",
    "\n",
    "\n",
    "    conv_output, conv_first_grad, conv_second_grad, conv_third_grad = gradient_function([x])\n",
    "    conv_output, conv_first_grad, conv_second_grad, conv_third_grad = conv_output[0], conv_first_grad[0], conv_second_grad[0], conv_third_grad[0]\n",
    "\n",
    "    #alphaを求める\n",
    "    global_sum = np.sum(conv_output.reshape((-1, conv_first_grad.shape[2])), axis=0)\n",
    "    alpha_num = conv_second_grad\n",
    "    alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((1,1,conv_first_grad.shape[2]))\n",
    "    alpha_denom = np.where(alpha_denom!=0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
    "    alphas = alpha_num / alpha_denom\n",
    "\n",
    "    #alphaの正規化\n",
    "    alpha_normalization_constant = np.sum(np.sum(alphas, axis = 0), axis = 0)\n",
    "    alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
    "    alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad.shape[2]))\n",
    "\n",
    "    #wの計算\n",
    "    weights = np.maximum(conv_first_grad, 0.0)\n",
    "    deep_linearization_weights = np.sum((weights * alphas).reshape((-1, conv_first_grad.shape[2])))\n",
    "\n",
    "    #Lの計算\n",
    "    grad_CAM_map = np.sum(deep_linearization_weights * conv_output, axis=2)\n",
    "    grad_CAM_map = np.maximum(grad_CAM_map, 0)\n",
    "    grad_CAM_map = grad_CAM_map / np.max(grad_CAM_map)\n",
    "    \n",
    "    #ヒートマップを描く\n",
    "    print(\"出力：\" + str(np.shape(grad_CAM_map)))\n",
    "    #grad_CAM_map = cv2.resize(grad_CAM_map, (row, col), cv2.INTER_LINEAR)\n",
    "    #jetcam = cv2.applyColorMap(np.uint8(255 * grad_CAM_map), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
    "    #jetcam = (np.float32(jetcam) + x / 2)   # もとの画像に合成\n",
    "\n",
    "    return grad_CAM_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# layer_name : 最後のconvolution層直後のactivation層の名前を確認したい．\n",
    "# activation層（活性化関数を使っている層）がconvolution層に含まれている場合\n",
    "# ⇒ convolution層の名前でよい．\n",
    "# 層の名前はmodel.summary()で確認できる．\n",
    "model.summary()\n",
    "# これよりconv2d_4が対象のactivation層になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力：(5, 28, 28, 1)\n",
      "出力：(14, 14)\n"
     ]
    }
   ],
   "source": [
    "#次のTodo★\n",
    "#以下の関数を通るようにする．（上で実装したpredictionを通るようにする．）\n",
    " \n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras import backend as K\n",
    "\n",
    "# Model : 上で定義したmodel\n",
    "model = model\n",
    "\n",
    "#Model : VGG16 (.h5のダウンロードに10分かかる)\n",
    "#model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)\n",
    "\n",
    "#Model : Resvet(.h5のダウンロードに10分かかる)\n",
    "#model = ResNet50(weights = 'imagenet')\n",
    "\n",
    "img = test[0:5] #shapeは datanum(5) * 28pix * 28pix * 1の形に\n",
    "\n",
    "target_layer = 'conv2d_4'\n",
    "row = 28\n",
    "col = 28\n",
    "\n",
    "img_GCAMplusplus = Grad_Cam_plus_plus(model, target_layer, img, row, col)\n",
    "#img_Gplusplusname = args.image_path+\"_GCAM++_%s.jpg\"%args.model\n",
    "#cv2.imwrite(img_Gplusplusname, img_GCAMplusplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次回Todo\n",
    "# cv2をimportして以下の計算を回す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot resize an array that references or is referenced\nby another array in this way.\nUse the np.resize function or refcheck=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f624fcb22e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_GCAMplusplus_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_GCAMplusplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot resize an array that references or is referenced\nby another array in this way.\nUse the np.resize function or refcheck=False"
     ]
    }
   ],
   "source": [
    "img_GCAMplusplus_resized = img_GCAMplusplus.resize((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grad_CAM_map = cv2.resize(grad_CAM_map, (row, col), cv2.INTER_LINEAR)\n",
    "#jetcam = cv2.applyColorMap(np.uint8(255 * grad_CAM_map), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
    "#jetcam = (np.float32(jetcam) + x / 2)   # もとの画像に合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_GCAMplusplus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 : 線形補間<br>\n",
    "- https://qiita.com/ground0state/items/5fa0743837f1bcb374ca\n",
    "\n",
    "2 : テストデータとバリデーションデータの分割\n",
    "- from sklearn.model_selection import train_test_split\n",
    "\n",
    "3 : 混合行列の描写\n",
    " - 混同行列（confusion matrix）はクラス分類問題の結果を「実際のクラス」と「予測したクラス」を軸にしてまとめたもの。\n",
    " - from sklearn.metrics import confusion_matrix \n",
    " \n",
    "4 : ループ処理を楽にするitertools \n",
    " - https://qiita.com/__cooper/items/ff1d3d71088abb5d0849\n",
    "```\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "```\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "5 : pandasのデータの抜き取り\n",
    "- X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "6 : ヒストグラム等，numpyが使いづらい時はseabornを使うと良い．\n",
    "- g = sns.countplot(Y_train)\n",
    "\n",
    "7 : isnull(), any(), describe()の併せ技（dataのチェックが出来る．）\n",
    "X_train.isnull().any().describe()\n",
    "\n",
    "8 : \"to_categorical\" (from keras.utils.np_utils import to_categorical)\n",
    "- Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "- e.g. Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "\n",
    "9 : 訓練データとバリデーションデータへの分割\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)\n",
    "\n",
    "10 : kerasの使い方．\n",
    "- model = Sequential() : \n",
    "- model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1))) : \n",
    "- model.add(MaxPool2D(pool_size=(2,2)))\n",
    "- model.add(Dropout(0.25))\n",
    "- model.add(Flatten())\n",
    "- model.add(Dense(256, activation = \"relu\")) # 出力は256個のノード\n",
    "\n",
    "11 : Optimizerの使い方\n",
    " - optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    " \n",
    "12 : Compile model \n",
    "- model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "13 : set learning rate\n",
    "- learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "14 :sa\n",
    "\n",
    "\n",
    "* 次回Todo\n",
    " - セル19から作る．\n",
    " - 上の関数からまとめノート作っておく．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
