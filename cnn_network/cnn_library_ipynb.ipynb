{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/TakehikoEsaka/kaggle_digit_recognizer/blob/master/cnn_library_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rX8mhOLljYeM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "BZSlp3DAjdYf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# 初心者のための TensorFlow 2.0 入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUNzJc4jTj6G"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/quickstart/beginner\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRXLphinx2fF"
   },
   "source": [
    "Note: これらのドキュメントは私たちTensorFlowコミュニティが翻訳したものです。コミュニティによる 翻訳は**ベストエフォート**であるため、この翻訳が正確であることや[英語の公式ドキュメント](https://www.tensorflow.org/?hl=en)の 最新の状態を反映したものであることを保証することはできません。 この翻訳の品質を向上させるためのご意見をお持ちの方は、GitHubリポジトリ[tensorflow/docs](https://github.com/tensorflow/docs)にプルリクエストをお送りください。 コミュニティによる翻訳やレビューに参加していただける方は、 [docs-ja@tensorflow.org メーリングリスト](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ja)にご連絡ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgJT2G3OwwlT"
   },
   "source": [
    "この短いイントロダクションでは [Keras](https://www.tensorflow.org/guide/keras/overview) を使って下記のことを行います。\n",
    "\n",
    "1. 画像を分類するニューラルネットワークを構築する\n",
    "2. このニューラルネットワークを訓練する\n",
    "3. そして最後に、モデルの正解率を評価する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiH7AC-NTniF"
   },
   "source": [
    "このファイルは [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) の notebook ファイルです。 Python プログラムはブラウザ上で直接実行されます。TensorFlow を学んだり使ったりするには最良の方法です。Google Colab のnotebook の実行方法は以下のとおりです。\n",
    "\n",
    "1. Pythonランタイムへの接続：メニューバーの右上で「接続」を選択します。\n",
    "2. ノートブックのコードセルをすべて実行：「ランタイム」メニューから「すべてのセルを実行」を選択します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCJXrk_vwwlV"
   },
   "source": [
    "TensorFlow 2 のパッケージをダウンロードしてインストールします。プログラムに TensorFlow をインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow をインストール\n",
    "try:\n",
    "  # %tensorflow_version は Colab 上でのみ利用可能\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "[MNIST データセット](http://yann.lecun.com/exdb/mnist/)をロードして準備します。サンプルを整数から浮動小数点数に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FP5258xjs-v"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPZ68wASog_I"
   },
   "source": [
    "層を積み重ねて`tf.keras.Sequential`モデルを構築します。訓練のためにオプティマイザと損失関数を選びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzRbn7q9TgQA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aj_0FYtbTnZI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4El-winTgpH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xeUhSD2FYszI"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1193a12ae08f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Perception Branch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#ここにx1とx2_1を足し合わせる記述を記載\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#アダマール積\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#Attention Branch Network\n",
    "\n",
    "# 分岐型ネットワークでの定義\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D,\\\n",
    "                        MaxPool2D, GlobalAveragePooling2D, BatchNormalization\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "original_im = Input(shape=(28,28,1))\n",
    "x = Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same',\n",
    "           activation='relu', input_shape = (28,28,1))(original_im)\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5,), padding = \"Same\",\n",
    "           activation=\"relu\")(x)\n",
    "x1 = MaxPool2D(pool_size = (2,2), strides = (2,2))(x) #14*14*64\n",
    "\n",
    "# Attention Branch\n",
    "x2 = Conv2D(filters = 64, kernel_size = (5,5,), padding = \"Same\",\n",
    "           activation=\"relu\")(x1)\n",
    "x2 = Conv2D(filters = 64, kernel_size = (1,1,), padding = \"Same\",\n",
    "           activation=\"relu\")(x2)\n",
    "\n",
    "# Attention Branch 1\n",
    "x2_1 = Conv2D(filters = 64, kernel_size = (1,1,), padding = \"Same\",\n",
    "           activation=\"sigmoid\")(x2) #14*14*64\n",
    "\n",
    "# Attention Branch 2\n",
    "x2_2 = Conv2D(filters = 64, kernel_size = (1,1,), padding = \"Same\",\n",
    "           activation=\"relu\")(x2)\n",
    "x2_2 = GlobalAveragePooling2D(data_format = None)(x2_2) \n",
    "output = Dense(10, activation = \"softmax\")(x2_2)\n",
    "\n",
    "# Perception Branch\n",
    "#ここにx1とx2_1を足し合わせる記述を記載\n",
    "x4 = tf.keras.layers.multiply([x1, x2_1]) #アダマール積\n",
    "x4 = tf.keras.layers.add([x1, x4 + 1])\n",
    "x4 = Dense(512, activation = \"relu\")(x4) \n",
    "output = Dense(10, activation = \"softmax\")(x4)\n",
    "\n",
    "model = tf.keras.models.Model(inputs = original_im, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dzrwf_NJYtB9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4gLKnfRXoow"
   },
   "outputs": [],
   "source": [
    "# FCN\n",
    "# Todo : \n",
    "# ★model.summary()で画像サイズを見る。\n",
    "# ★画像の切り出しについて調べる。（labelmeをインストールhttps://github.com/wkentaro/labelme）\n",
    "# ★実際に学習と予測をしてみる。\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Flatten, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.engine.topology import Layer\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        n = s[0]\n",
    "        if s[1] == None:\n",
    "            h = None\n",
    "        else:\n",
    "            h = s[1] + 2 * self.padding[0]\n",
    "        if s[2] == None:\n",
    "            w = None\n",
    "        else:\n",
    "            w = s[2] + 2 * self.padding[1]\n",
    "        c = s[3]\n",
    "        return (n, h, w, c)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "\n",
    "class UserModel(object):\n",
    "\n",
    "    def __init__(self, cut_size, channel, category_count, optimizer):\n",
    "        self.cut_size = cut_size\n",
    "        self.channel = channel\n",
    "        self.category_count = category_count\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def __denseBlock(self, inputT, channels = 32):\n",
    "\n",
    "        out = ReflectionPadding2D((1,1))(inputT)\n",
    "        out = Conv2D(channels, (3, 3), activation='relu', padding='valid')(out)\n",
    "        out = Concatenate()([out, inputT])\n",
    "        out = Conv2D(channels, (1, 1), activation='relu')(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        return out\n",
    "\n",
    "    def __modelBody(self, inputT):\n",
    "\n",
    "        # 56*56\n",
    "        x = BatchNormalization()(inputT)\n",
    "        x = ReflectionPadding2D((2,2))(x)\n",
    "        x = Conv2D(16, (5, 5), strides=2, activation='relu', padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        # 28*28\n",
    "        x = self.__denseBlock(x)\n",
    "        x = self.__denseBlock(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "        # 14*14\n",
    "        x = self.__denseBlock(x)\n",
    "        x = self.__denseBlock(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        # 7*7\n",
    "        x = self.__denseBlock(x)\n",
    "        x = self.__denseBlock(x)\n",
    "        x = self.__denseBlock(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __clsModelSetup(self, input_img):\n",
    "\n",
    "        x = self.__modelBody(input_img)\n",
    "\n",
    "        x = AveragePooling2D((7, 7))(x)\n",
    "        x = Conv2D(self.category_count, (1, 1), activation='softmax', padding='valid')(x)\n",
    "\n",
    "        out = Flatten()(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __fcnModelSetup(self, input_img):\n",
    "\n",
    "        x = self.__modelBody(input_img)\n",
    "\n",
    "        x = AveragePooling2D((7, 7), strides=1, padding='same')(x)\n",
    "\n",
    "        out = Conv2D(self.category_count, (1, 1), activation='softmax', padding='valid')(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def getTrainModel(self):\n",
    "\n",
    "        input_img = Input(shape=(self.cut_size['height'], self.cut_size['width'], self.channel))\n",
    "        result = self.__clsModelSetup(input_img)\n",
    "        model = Model(input_img, result)\n",
    "        model.compile(optimizer=self.optimizer, loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def getCLSModel(self):\n",
    "\n",
    "        input_img = Input(shape=(self.cut_size['height'], self.cut_size['width'], self.channel))\n",
    "        result = self.__clsModelSetup(input_img)\n",
    "        model = Model(input_img, result)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def getFCNModel(self):\n",
    "\n",
    "        input_img = Input(shape=(None, None, self.channel))\n",
    "        result = self.__fcnModelSetup(input_img)\n",
    "        model = Model(input_img, result)\n",
    "\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alQZjZVeZeN0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUvVgGjdXorI"
   },
   "outputs": [],
   "source": [
    "# Autoencoder.変分下限いれたものがVAEになる。\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pW7WJRZqZdus"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rkcWOUUmXotP"
   },
   "outputs": [],
   "source": [
    "# GANの基本的な構造\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        #mnistデータ用の入力データサイズ\n",
    "        self.img_rows = 28 \n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # 潜在変数の次元数 \n",
    "        self.z_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # discriminatorモデル\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Generatorモデル\n",
    "        self.generator = self.build_generator()\n",
    "        # generatorは単体で学習しないのでコンパイルは必要ない\n",
    "        #self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        self.combined = self.build_combined1()\n",
    "        #self.combined = self.build_combined2()\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_shape=noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_combined1(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        return model\n",
    "\n",
    "    def build_combined2(self):\n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        valid = self.discriminator(img)\n",
    "        model = Model(z, valid)\n",
    "        model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Gl_ewcgXovH"
   },
   "outputs": [],
   "source": [
    "def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # mnistデータの読み込み\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # 値を-1 to 1に規格化\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Discriminatorの学習\n",
    "            # ---------------------\n",
    "\n",
    "            # バッチサイズの半数をGeneratorから生成\n",
    "            noise = np.random.normal(0, 1, (half_batch, self.z_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "\n",
    "            # バッチサイズの半数を教師データからピックアップ\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # discriminatorを学習\n",
    "            # 本物データと偽物データは別々に学習させる\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            # それぞれの損失関数を平均\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Generatorの学習\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "\n",
    "            # 生成データの正解ラベルは本物（1） \n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # 進捗の表示\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # 指定した間隔で生成画像を保存\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wEfFAIcabcoG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IIB66QJobcrG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4_F_SsrIYtI2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-pwP37ZYtR0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ix4mEL65on-w"
   },
   "source": [
    "モデルを訓練してから評価します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F7dTAzgHDUh7"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4JfEh7kvx6m"
   },
   "source": [
    "この画像分類器は、今回のデータセットで訓練した場合、最大98%程度の正解率となります。更に学ぶには[TensorFlow tutorials](https://www.tensorflow.org/tutorials/)を読んでください。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "beginner.ipynb のコピー",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
