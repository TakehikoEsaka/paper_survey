{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Dense, Input, merge\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data (画素値を0-1に)\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "# reshapeで[データ数, height, width, color_channels]\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and valdiation set\n",
    "# Set the random seed\n",
    "random_seed = 2\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, \\\n",
    "                                                test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some examples\n",
    "g = plt.imshow(X_train[1][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "（実装）\n",
    "- ★：VGG, ResNet, SGNetを実装する\n",
    "- ★：論文元を確認してすぐ使えるようにする\n",
    "- ★：ソーラーのデータで試してみる\n",
    "\n",
    "* 済： kerasのプロパティとメソッドに目を通す\n",
    "* 済：kerasのグローバルアベレージをFeature_Extractorに実装してFeatureMapを見れるようにする．\n",
    "* 済：kerasのレイヤー分岐について調べて，簡単なレイヤー分岐を作る． (keras レイヤー分岐で検索)\n",
    "    - layer2 = Conv2D(***)(layer1) 等の引き継ぎに関して理解\n",
    "    - keras.layers.merge.add, keras.layers.merge.concatenate を使ってレイヤーの統合を理解する． おそらくmodel = merge([processed_a, processed_b], mode='sum') \n",
    "    \n",
    "    GAPでFlattenする前の最終層をFeatureMapとして取り出す．\n",
    "- 済：seqential()でモデル定義\n",
    "    -> 1: attentionのGAPについて再度計算式を抑える．以下を参考に<br>\n",
    "    https://github.com/salty-vanilla/cnn_saliency/blob/master/mnist/cam_vis.ipynb <br>\n",
    "   https://github.com/salty-vanilla/cnn_saliency/blob/master/imagenet/cam.ipynb <br> \n",
    "- 済：28 * 28 のdigitiデータで訓練，jsonと重みファイルをゲット．以下のメソッドでkeras.modelクラスの構造と重みが得られるはず<br>\n",
    "    -> from keras.models import model_from_json <br>\n",
    "    -> model = model_from_json(open('digit_recognizer_model.json', 'r').read()) <br>\n",
    "    -> model.load_weights('mnist_mlp_weights.h5') <br>\n",
    "- 済：指定した部分までの重みをかけた結果を取得．以下のメッソドようなものが使えるはず．<br>\n",
    "    -> class_output = model.layers[-1].output <br>\n",
    "    -> conv_output = model.get_layer(layer_name).output <br>\n",
    "- 済：分岐型ネットワークでGAPを実装したモデルを書き直す\n",
    "- 済：json, h5ファイルを再度得る．(まとめも兼ねて)\n",
    "- 済：中間層途中結果 & 中間層重み を取得し，\\sum_{channel}^{class} w_{channnel}^{class} * f_{channel}(x,y)を計算\n",
    "- 済：FeatureMapを描写\n",
    "- 済： Perception_Branchの実装\n",
    "- 済：複雑なモデル実装という以下のチュートリアルをする．https://qiita.com/mokemokechicken/items/483099fead460dc3a6fa\n",
    "- 済：x2_2 = Conv2D(filters = 64, kernel_size = (1,1,), padding = \"Same\",\n",
    "           activation=\"sigmoid\")(x2) をConv, BatchNormalization, Sigmoidに分解して記載\n",
    "- 済：keras.layeのaddを実装\n",
    "- 済：Attention Mapの描写\n",
    "- 済：attention_mapのclassの数が10ではなく，64に見えるけどどのように処理すればいいのか?（論文中のhとwが何を意味するかを知りたい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Construct Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Conv2D,\\\n",
    "                        MaxPool2D, GlobalAveragePooling2D, BatchNormalization\n",
    "original_im = Input(shape=(28,28,1))\n",
    "x = Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same',\n",
    "           activation='relu', input_shape = (28,28,1))(original_im)\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5,), padding = \"Same\",\n",
    "           activation=\"relu\")(x)\n",
    "x = MaxPool2D(pool_size = (2,2), strides = (2,2))(x)\n",
    "x = GlobalAveragePooling2D(data_format = None)(x) #Flattenはしなくてもいい．\n",
    "output = Dense(10, activation = \"softmax\")(x) # Denseは全結合層\n",
    "\n",
    "cam_model = keras.models.Model(inputs = original_im, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 52,746\n",
      "Trainable params: 52,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cam_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "cam_model.compile(optimizer=optimizer, \n",
    "              loss=[\"categorical_crossentropy\"],metrics=['accuracy'])\n",
    "#lr : 学習率\n",
    "# rho, epsilon : rmsiのパラメータ\n",
    "# softmaxは出力が10クラスの確率[0,0,0.8,0,0,0,0,0,0.2,0] = 足したら1\n",
    "# カテゴリカルクロスエントリピー ：ラベル[0,0,1,0,0,0,0,0,0,0] とエントロピー計算\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \n",
    "                        patience=3, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "# monitorはval_loss,val_accuracy,loss,accuracyが設定可能．\n",
    "\n",
    "epochs = 1 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.2990 - accuracy: 0.0000e+00 - val_loss: 2.2450 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# DataAugumantationなし(Generator利用せずに計算)\n",
    "cam_model_history = cam_model.fit(x = X_train[0:10], y = Y_train[0:10], validation_split = 0.2, \\\n",
    "                 batch_size = batch_size, callbacks=[learning_rate_reduction])\n",
    "# callbacksは学習率のコントロールを示している．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataaugumantation あり -> generatorを使ってRAMに乗らなくても回るようにする．\n",
    "# datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         zoom_range = 0.1, # Randomly zoom image \n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#         horizontal_flip=False,  # randomly flip images\n",
    "#         vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# # Y_trainはリスト2つに\n",
    "# history = cam_model.fit_generator(datagen.flow(X_train[0:10], Y_train[0:10], batch_size=batch_size),\n",
    "#                               epochs = epochs, validation_data = (X_val[0:10],Y_val[0:10]),\n",
    "#                               verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "# #                               , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelの構造保存\n",
    "json_string = cam_model.to_json()\n",
    "open('digit_recognizer_model.json', 'w').write(json_string)\n",
    "\n",
    "#重みの保存\n",
    "cam_model.save_weights('digit_recognizer_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルと重みの読込，\n",
    "from keras.models import model_from_json\n",
    "cam_model = model_from_json(open('digit_recognizer_model.json', 'r').read())\n",
    "cam_model.load_weights('digit_recognizer_weights.h5')\n",
    "\n",
    "#summaryをテキストとして保存\n",
    "with open(\"output.txt\", \"w\") as fp:\n",
    "    cam_model.summary(print_fn=lambda x: fp.write(x + \"\\r\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: max_pooling2d_2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-41a0f265c09c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'max_pooling2d_2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m intermediate_layer_model = Model(inputs=cam_model.input,\n\u001b[0;32m----> 6\u001b[0;31m                                  outputs=cam_model.get_layer(layer_name).output)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintermediate_layer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: max_pooling2d_2"
     ]
    }
   ],
   "source": [
    "from keras import backend as K #Keras API\n",
    "\n",
    "#中間層の結果を取得\n",
    "layer_name = 'max_pooling2d_2'\n",
    "intermediate_layer_model = Model(inputs=cam_model.input,\n",
    "                                 outputs=cam_model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(X_train[0:1])\n",
    "print(np.shape(intermediate_output))\n",
    "\n",
    "# Keras APIを使用\n",
    "ret = cam_model.predict(X_train[0:1], 1, 1)\n",
    "get_layer_output = K.function([cam_model.get_layer(layer_name).input],\n",
    "                                  [cam_model.get_layer(layer_name).output])\n",
    "layer_output = get_layer_output([X_train[0:1],])\n",
    "print(np.shape(layer_output))\n",
    "np.save('./max_pooling2d_10.npy', layer_output[0], allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 32)\n",
      "(32,)\n",
      "(5, 5, 32, 64)\n",
      "(64,)\n",
      "(64, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "#中間の重みを取得\n",
    "w = cam_model.get_weights()\n",
    "for i in range(len(w)):\n",
    "    print(w[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'intermediate_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1922a4cfd160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# FeatureMapを10クラス分計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 全クラスのfeaturemap計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intermediate_output' is not defined"
     ]
    }
   ],
   "source": [
    "# FeatureMapを10クラス分計算\n",
    "print(w[-2].shape)\n",
    "print(intermediate_output[0].shape)\n",
    "\n",
    "# 全クラスのfeaturemap計算\n",
    "feature_map, = intermediate_output @ w[-2]\n",
    "print(feature_map.shape)\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(feature_map[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention Branch Network\n",
    "\n",
    "# 分岐型ネットワークでの定義\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, Activation,\\\n",
    "                        MaxPool2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.layers.merge import add, multiply\n",
    "from keras import backend as K\n",
    "\n",
    "original_im = Input(shape=(28,28,1))\n",
    "x1 = Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same',\n",
    "           activation='relu', input_shape = (28,28,1))(original_im)\n",
    "x1 = Conv2D(filters = 64, kernel_size = (5,5,), padding = \"Same\",\n",
    "           activation=\"relu\")(x1)\n",
    "feature_map = MaxPool2D(pool_size = (2,2), strides = (2,2))(x1)\n",
    "\n",
    "# Attention Branch\n",
    "x2 = Conv2D(filters = 64, kernel_size = (5,5,), padding = \"Same\",\n",
    "           activation=\"relu\")(feature_map) # Attention Branchの具体的なClassifierの構造はここを変化させる．\n",
    "x2 = BatchNormalization(axis = 1)(x2) # ★ axis = 1であってるか確認\n",
    "x2 = Conv2D(filters = 64, kernel_size = (1,1,), padding = \"Same\",\n",
    "           activation=\"relu\")(x2)\n",
    "x2_1 = Conv2D(filters = 64, kernel_size = (1,1,), padding = \"Same\",\n",
    "           activation=\"relu\")(x2)\n",
    "\n",
    "# Attention Branch 分岐１\n",
    "x2_1 = Conv2D(filters = 64, kernel_size = (1,1,), padding = \"Same\")(x2_1)\n",
    "x2_1 = GlobalAveragePooling2D(data_format = \"channels_last\")(x2_1) \n",
    "x2_1 = Dense(10, activation = \"softmax\")(x2_1)\n",
    "output1 = Activation(\"softmax\")(x2_1)\n",
    "\n",
    "# Attention Branch 分岐2\n",
    "x2 = Conv2D(filters = 1, kernel_size = (1,1,), padding = \"Same\")(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "attention_map = Activation(\"sigmoid\")(x2)\n",
    "\n",
    "# Perception Branch\n",
    "# ★ 足し算のやり方調べる．\n",
    "#one = K.variable(np.ones((14,14,64)))\n",
    "#kari = add([feature_map, one], axis = 2)\n",
    "x4 = multiply([feature_map, attention_map])\n",
    "# ★ PerceptionBranchの具体的なclassifierの構造はここを変化させる．\n",
    "x4 = Conv2D(filters = 64, kernel_size = (3,3,), padding = \"Same\",\n",
    "           activation=\"relu\")(x4)\n",
    "x4 = MaxPool2D(pool_size = (2,2), strides = (2,2))(x4)\n",
    "x4 = Flatten(data_format=None)(x4)\n",
    "x4 = Dense(512, activation = \"relu\")(x4)\n",
    "output2 = Dense(10, activation = \"softmax\")(x4)\n",
    "\n",
    "ab_model = keras.models.Model(inputs = original_im, outputs = [output1, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 512)\n",
      "(None, 14, 14, 1)\n",
      "(None, 14, 14, 64)\n",
      "(None, 10)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "print(str(x4.get_shape()))\n",
    "print(str(attention_map.get_shape()))\n",
    "print(str(feature_map.get_shape()))\n",
    "print(str(x2_1.get_shape()))\n",
    "print(str(output1.get_shape()))\n",
    "print(str(output2.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 4.0059 - activation_1_loss: 2.2878 - dense_3_loss: 1.6944 - activation_1_accuracy: 0.1520 - dense_3_accuracy: 0.4050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 2.8517 - activation_1_loss: 2.2150 - dense_3_loss: 0.6257 - activation_1_accuracy: 0.2190 - dense_3_accuracy: 0.8280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 2.4748 - activation_1_loss: 2.1893 - dense_3_loss: 0.2871 - activation_1_accuracy: 0.2320 - dense_3_accuracy: 0.9140\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 2.3875 - activation_1_loss: 2.1756 - dense_3_loss: 0.2081 - activation_1_accuracy: 0.2610 - dense_3_accuracy: 0.9300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 2.2999 - activation_1_loss: 2.1564 - dense_3_loss: 0.1391 - activation_1_accuracy: 0.2780 - dense_3_accuracy: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 2.2351 - activation_1_loss: 2.1315 - dense_3_loss: 0.0988 - activation_1_accuracy: 0.3230 - dense_3_accuracy: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 2.1872 - activation_1_loss: 2.1334 - dense_3_loss: 0.0562 - activation_1_accuracy: 0.3260 - dense_3_accuracy: 0.9820\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 2.1735 - activation_1_loss: 2.1106 - dense_3_loss: 0.0647 - activation_1_accuracy: 0.3540 - dense_3_accuracy: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 2.1164 - activation_1_loss: 2.0912 - dense_3_loss: 0.0233 - activation_1_accuracy: 0.3710 - dense_3_accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 2.1180 - activation_1_loss: 2.0802 - dense_3_loss: 0.0344 - activation_1_accuracy: 0.4000 - dense_3_accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "# DataAugumantationなし \n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "ab_model.compile(optimizer=optimizer, \n",
    "              loss=[\"categorical_crossentropy\", \"categorical_crossentropy\"], \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='loss', \n",
    "                        patience=3, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "# monitor出来るLossは，loss,dense_11_loss,dense_13_loss,dense_11_accuracy,dense_13_accuracyの5つ\n",
    "\n",
    "epochs = 10 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86\n",
    "\n",
    "# Y_trainはリスト2つに\n",
    "ab_model_history = ab_model.fit(x = X_train[0:1000], y = [Y_train[0:1000],Y_train[0:1000]], validation_split = 0.0, \\\n",
    "                 epochs=epochs, batch_size = batch_size, callbacks=[learning_rate_reduction])\n",
    "\n",
    "# callbacksは学習率のコントロールを示している．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ab_model_summary.txt\", \"w\") as fp:\n",
    "    ab_model.summary(print_fn = lambda x : fp.write(x + \"\\r\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelの構造保存\n",
    "json_string = ab_model.to_json()\n",
    "open('ab_model.json', 'w').write(json_string)\n",
    "\n",
    "#重みの保存\n",
    "ab_model.save_weights('ab_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象のmodel名を入れる\n",
    "history = ab_model_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 32)   832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 64)   51264       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 64)   102464      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 64)   56          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 64)   4160        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 14, 14, 1)    65          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 1)    4           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 1)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 14, 14, 64)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 14, 14, 64)   4160        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 64)   36928       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 14, 14, 64)   4160        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 64)     0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3136)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           650         global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1606144     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           5130        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,816,017\n",
      "Trainable params: 1,815,987\n",
      "Non-trainable params: 30\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ab_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'activation_32_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-056283320c30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activation_32_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ab_branch loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dense_51_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"p_branch loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlegend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'activation_32_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history['activation_32_loss'], color='y', label=\"ab_branch loss\")\n",
    "ax[0].plot(history['dense_51_loss'], color='r', label=\"p_branch loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history['activation_32_accuracy'], color='y',label=\"ab_branch accuracy\")\n",
    "ax[1].plot(history['dense_51_accuracy'], color='r',label=\"p_branch accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 14, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K #Keras API\n",
    "\n",
    "#中間層の結果を取得\n",
    "layer_name = 'activation_2'\n",
    "intermediate_layer_model = Model(inputs=ab_model.input,\n",
    "                                 outputs=ab_model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(X_train[2000:3000])\n",
    "print(np.shape(intermediate_output))\n",
    "\n",
    "# Keras APIを使用\n",
    "#ret = cam_model.predict(X_train[0:1], 1, 1)\n",
    "# get_layer_output = K.function([cam_model.get_layer(layer_name).input],\n",
    "#                                   [cam_model.get_layer(layer_name).output])\n",
    "# layer_output = get_layer_output([X_train[0:1],])\n",
    "# print(np.shape(layer_output))\n",
    "np.save('./attention_map.npy', intermediate_output, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Text' object has no property 'labelbottom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d76a5832e605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2000\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelbottom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mxticks\u001b[0;34m(ticks, labels, **kwargs)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Text xticklabel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# bbox can be None, so use another sentinel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meventson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_update_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meventson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_update_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_property\u001b[0;34m(self, k, v)\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                     raise AttributeError('{!r} object has no property {!r}'\n\u001b[0;32m--> 970\u001b[0;31m                                          .format(type(self).__name__, k))\n\u001b[0m\u001b[1;32m    971\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Text' object has no property 'labelbottom'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD0AAAA3CAYAAAC/+UKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEAUlEQVRoge2ZX4hUVRzHP3f+kIv0Z1k0ZteyiPXXH6IYNcOwzKfFjHpYKoUKFDEDoXzxIbOlQG3tIcqFIoOiB98i6iHwxQmjjDWVNOhnVA/j7kKLW4iyrsyd68M9s1x0nTkz94wzcucLw8yce873/r6ce84939/PC4KApCHV6gBagY7opKAjOilIpOhMXAIRWQJ8CfQA54BXVPXPuLzNhIuZ/gQYUdUlwAjwqQPOpsKLczgRkYXAGaBHVX0RSRPOdr+qTlYZdwuwHJgA/IYDCJEGcsCoqs7YDIj7eN8FjKmqD2CEj5v264omFHwk5r2vxirgR5uOsdd0g5gAODt2kZIf7xicSXss6ps/y2k1JtYdoQj0iUg68nj3mvZq8AFKfkCp5Ozsb71MYm1kqvovcBJYb5rWAyeqred68Pu9j3B+1xoujf3Aht7HXVACbnbv14BtInIG2Gb+x8L/r+eZLh5m90wX9+wbpf+BQT7/ZQ+T6/pjBwsO1rSq/gGscBDLLLKvbgbguZl55LrzPDbj4f/9qzP+Vm1kVTF/xVZ29K7m6cAnV86yrrAZum5l5PgiIP65p22Poe+PFxiYOsJlL8C7fSEbVg0xNH7YCXfbigbY0buaN48NgZfim4ljznjbWvTO9xYD4BdPO+Vta9HZgY3gpRge/Nopb9uK/ujONQTlMvvz7/Cuo7VcQVuKzqYzbPxsOaVDX/Dhxd+c87flK2tq5AUyS9cyr++ppvDXFC0iPcBXwH3AZcIX5RZVnRSRADgFlE33l1X1VOyg1m4iKJdrd2yU36JPAAyragFARPYBe4FN5vpKVb3gNCovBSUra9wQaopW1SmgEGk6CmxtVkAAvv7Mdy8dahp/XWtaRFKEgr+NNBdEJAN8DwxZZi/SEHrhuXDHwFthcJm5r0cR4Uhb3DccY9vR4GPgArDf/L9bVYsichvhun8b2GnBkwMq5t8VcsBfNh2tRYvIB0A/8KyqlgFUtWi+z4vIAWC7Jd0oYXrHaY7MdoCVaBHZDSwFnqk8viLSDVxS1WnzeA8SJhRqwnBY5bMsYTXDFdTMhorIQ8BpwqzntGn+BxgmTPcGQBb4CXjD+U7eBMRKAd+saMtjaLPREZ0UdEQnBYkU3RI/XW9N27W9bdVM11vTrthbUdWHCU9geyPXV6rqo+ZT08/fcNGmpp0HDpqmg0BeRBZcb4yqTlX8vMFRYHGjMbRipq+paQOVmnZNVLG3J0Vkjyn4V8XNuJHNZW+XAU8CDxLa26pohejZmjZAHTXtqL19cS57CxwAnqjFc8NFN1rTjtjb56P2VkS6zG9re9sSlyUi9xO+srqB/whfWVqlv1N727GWSUFHdFLQEZ0UdEQnBVcAyuWGlEsAhJEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    plt.subplot(10,2,2*i+1)\n",
    "    plt.imshow(X_train[2000 + i,:,:,0])\n",
    "    plt.xticks()\n",
    "    plt.subplot(10,2,2*i+2)\n",
    "    plt.imshow(intermediate_output[i,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = cam_model.predict(X_val)\n",
    "# Convert predictions classes \"FROM\" one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations \"FROM\" one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "\n",
    "#あるカラムだけ1で他のカラムは0な行列の表現。カテゴリー変数でよく使います。\n",
    "#古典的な統計の教科書では「ダミー変数」という言い方もします。\n",
    "#PandasのOneHotベクトルを作る関数get_dummiesはこれが由来です。\n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = cam_model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_num * class_num\n",
    "print(results.shape)\n",
    "\n",
    "predicted = np.argmax(results, axis = 1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-Cam ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import PIL\n",
    "import numpy as np\n",
    "import argparse\n",
    "import keras\n",
    "import sys\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Sequential\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grad_Cam_plus_plus(input_model, layer_name, x, row, col):\n",
    "\n",
    "    model = input_model\n",
    "\n",
    "    # 前処理\n",
    "    #X = np.expand_dims(x, axis=0)\n",
    "    #X = X.astype('float32')\n",
    "    #preprocessed_input = X / 255.0\n",
    "\n",
    "    # 予測クラスの算出\n",
    "    #predictions = model.predict(preprocessed_input)\n",
    "    print(\"入力：\" + str(x.shape))\n",
    "    predictions = model.predict(x)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "\n",
    "    #  使用する重みの抽出、高階微分の計算\n",
    "    class_output = model.layers[-1].output\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = K.gradients(class_output, conv_output)[0]\n",
    "    #first_derivative：１階微分\n",
    "    first_derivative = K.exp(class_output)[0][class_idx] * grads\n",
    "    #second_derivative：２階微分\n",
    "    second_derivative = K.exp(class_output)[0][class_idx] * grads * grads\n",
    "    #third_derivative：３階微分\n",
    "    third_derivative = K.exp(class_output)[0][class_idx] * grads * grads * grads\n",
    "\n",
    "    #関数の定義\n",
    "    gradient_function = K.function([model.input], [conv_output, first_derivative, second_derivative, third_derivative])  # model.inputを入力すると、conv_outputとgradsを出力する関数\n",
    "\n",
    "\n",
    "    conv_output, conv_first_grad, conv_second_grad, conv_third_grad = gradient_function([x])\n",
    "    conv_output, conv_first_grad, conv_second_grad, conv_third_grad = conv_output[0], conv_first_grad[0], conv_second_grad[0], conv_third_grad[0]\n",
    "\n",
    "    #alphaを求める\n",
    "    global_sum = np.sum(conv_output.reshape((-1, conv_first_grad.shape[2])), axis=0)\n",
    "    alpha_num = conv_second_grad\n",
    "    alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((1,1,conv_first_grad.shape[2]))\n",
    "    alpha_denom = np.where(alpha_denom!=0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
    "    alphas = alpha_num / alpha_denom\n",
    "\n",
    "    #alphaの正規化\n",
    "    alpha_normalization_constant = np.sum(np.sum(alphas, axis = 0), axis = 0)\n",
    "    alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
    "    alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad.shape[2]))\n",
    "\n",
    "    #wの計算\n",
    "    weights = np.maximum(conv_first_grad, 0.0)\n",
    "    deep_linearization_weights = np.sum((weights * alphas).reshape((-1, conv_first_grad.shape[2])))\n",
    "\n",
    "    #Lの計算\n",
    "    grad_CAM_map = np.sum(deep_linearization_weights * conv_output, axis=2)\n",
    "    grad_CAM_map = np.maximum(grad_CAM_map, 0)\n",
    "    grad_CAM_map = grad_CAM_map / np.max(grad_CAM_map)\n",
    "    \n",
    "    #ヒートマップを描く\n",
    "    print(\"出力：\" + str(np.shape(grad_CAM_map)))\n",
    "    #grad_CAM_map = cv2.resize(grad_CAM_map, (row, col), cv2.INTER_LINEAR)\n",
    "    #jetcam = cv2.applyColorMap(np.uint8(255 * grad_CAM_map), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
    "    #jetcam = (np.float32(jetcam) + x / 2)   # もとの画像に合成\n",
    "\n",
    "    return grad_CAM_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# layer_name : 最後のconvolution層直後のactivation層の名前を確認したい．\n",
    "# activation層（活性化関数を使っている層）がconvolution層に含まれている場合\n",
    "# ⇒ convolution層の名前でよい．\n",
    "# 層の名前はmodel.summary()で確認できる．\n",
    "model.summary()\n",
    "# これよりconv2d_4が対象のactivation層になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力：(5, 28, 28, 1)\n",
      "出力：(14, 14)\n"
     ]
    }
   ],
   "source": [
    "#次のTodo★\n",
    "#以下の関数を通るようにする．（上で実装したpredictionを通るようにする．）\n",
    " \n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras import backend as K\n",
    "\n",
    "# Model : 上で定義したmodel\n",
    "model = model\n",
    "\n",
    "#Model : VGG16 (.h5のダウンロードに10分かかる)\n",
    "#model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)\n",
    "\n",
    "#Model : Resvet(.h5のダウンロードに10分かかる)\n",
    "#model = ResNet50(weights = 'imagenet')\n",
    "\n",
    "img = test[0:5] #shapeは datanum(5) * 28pix * 28pix * 1の形に\n",
    "\n",
    "target_layer = 'conv2d_4'\n",
    "row = 28\n",
    "col = 28\n",
    "\n",
    "img_GCAMplusplus = Grad_Cam_plus_plus(model, target_layer, img, row, col)\n",
    "#img_Gplusplusname = args.image_path+\"_GCAM++_%s.jpg\"%args.model\n",
    "#cv2.imwrite(img_Gplusplusname, img_GCAMplusplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次回Todo\n",
    "# cv2をimportして以下の計算を回す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot resize an array that references or is referenced\nby another array in this way.\nUse the np.resize function or refcheck=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f624fcb22e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_GCAMplusplus_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_GCAMplusplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot resize an array that references or is referenced\nby another array in this way.\nUse the np.resize function or refcheck=False"
     ]
    }
   ],
   "source": [
    "img_GCAMplusplus_resized = img_GCAMplusplus.resize((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grad_CAM_map = cv2.resize(grad_CAM_map, (row, col), cv2.INTER_LINEAR)\n",
    "#jetcam = cv2.applyColorMap(np.uint8(255 * grad_CAM_map), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
    "#jetcam = (np.float32(jetcam) + x / 2)   # もとの画像に合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_GCAMplusplus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# FCN\n",
    "# Todo : \n",
    "# ★model.summary()で画像サイズを見る。\n",
    "# ★画像の切り出しについて調べる。（labelmeをインストールhttps://github.com/wkentaro/labelme）\n",
    "# ★実際に学習と予測をしてみる。\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Flatten, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.engine.topology import Layer\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        n = s[0]\n",
    "        if s[1] == None:\n",
    "            h = None\n",
    "        else:\n",
    "            h = s[1] + 2 * self.padding[0]\n",
    "        if s[2] == None:\n",
    "            w = None\n",
    "        else:\n",
    "            w = s[2] + 2 * self.padding[1]\n",
    "        c = s[3]\n",
    "        return (n, h, w, c)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "\n",
    "class UserModel(object):\n",
    "\n",
    "    def __init__(self, cut_size, channel, category_count, optimizer):\n",
    "        self.cut_size = cut_size\n",
    "        self.channel = channel\n",
    "        self.category_count = category_count\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def __denseBlock(self, inputT, channels = 32):\n",
    "\n",
    "        out = ReflectionPadding2D((1,1))(inputT)\n",
    "        out = Conv2D(channels, (3, 3), activation='relu', padding='valid')(out)\n",
    "        out = Concatenate()([out, inputT])\n",
    "        out = Conv2D(channels, (1, 1), activation='relu')(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        return out\n",
    "\n",
    "    def __modelBody(self, inputT):\n",
    "\n",
    "        # 56*56\n",
    "        x = BatchNormalization()(inputT)\n",
    "        x = ReflectionPadding2D((2,2))(x)\n",
    "        x = Conv2D(16, (5, 5), strides=2, activation='relu', padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        # 28*28\n",
    "        x = self.__denseBlock(x)\n",
    "        x = self.__denseBlock(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "        # 14*14\n",
    "        x = self.__denseBlock(x)\n",
    "        x = self.__denseBlock(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        # 7*7\n",
    "        x = self.__denseBlock(x)\n",
    "        x = self.__denseBlock(x)\n",
    "        x = self.__denseBlock(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __clsModelSetup(self, input_img):\n",
    "\n",
    "        x = self.__modelBody(input_img)\n",
    "\n",
    "        x = AveragePooling2D((7, 7))(x)\n",
    "        x = Conv2D(self.category_count, (1, 1), activation='softmax', padding='valid')(x)\n",
    "\n",
    "        out = Flatten()(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __fcnModelSetup(self, input_img):\n",
    "\n",
    "        x = self.__modelBody(input_img)\n",
    "\n",
    "        x = AveragePooling2D((7, 7), strides=1, padding='same')(x)\n",
    "\n",
    "        out = Conv2D(self.category_count, (1, 1), activation='softmax', padding='valid')(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def getTrainModel(self):\n",
    "\n",
    "        input_img = Input(shape=(self.cut_size['height'], self.cut_size['width'], self.channel))\n",
    "        result = self.__clsModelSetup(input_img)\n",
    "        model = Model(input_img, result)\n",
    "        model.compile(optimizer=self.optimizer, loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def getCLSModel(self):\n",
    "\n",
    "        input_img = Input(shape=(self.cut_size['height'], self.cut_size['width'], self.channel))\n",
    "        result = self.__clsModelSetup(input_img)\n",
    "        model = Model(input_img, result)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def getFCNModel(self):\n",
    "\n",
    "        input_img = Input(shape=(None, None, self.channel))\n",
    "        result = self.__fcnModelSetup(input_img)\n",
    "        model = Model(input_img, result)\n",
    "\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder.変分下限いれたものがVAEになる。\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GANの基本的な構造\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        #mnistデータ用の入力データサイズ\n",
    "        self.img_rows = 28 \n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # 潜在変数の次元数 \n",
    "        self.z_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # discriminatorモデル\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Generatorモデル\n",
    "        self.generator = self.build_generator()\n",
    "        # generatorは単体で学習しないのでコンパイルは必要ない\n",
    "        #self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        self.combined = self.build_combined1()\n",
    "        #self.combined = self.build_combined2()\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_shape=noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_combined1(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        return model\n",
    "\n",
    "    def build_combined2(self):\n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        valid = self.discriminator(img)\n",
    "        model = Model(z, valid)\n",
    "        model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # mnistデータの読み込み\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # 値を-1 to 1に規格化\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Discriminatorの学習\n",
    "            # ---------------------\n",
    "\n",
    "            # バッチサイズの半数をGeneratorから生成\n",
    "            noise = np.random.normal(0, 1, (half_batch, self.z_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "\n",
    "            # バッチサイズの半数を教師データからピックアップ\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # discriminatorを学習\n",
    "            # 本物データと偽物データは別々に学習させる\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            # それぞれの損失関数を平均\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Generatorの学習\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "\n",
    "            # 生成データの正解ラベルは本物（1） \n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # 進捗の表示\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # 指定した間隔で生成画像を保存\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 : 線形補間<br>\n",
    "- https://qiita.com/ground0state/items/5fa0743837f1bcb374ca\n",
    "\n",
    "2 : テストデータとバリデーションデータの分割\n",
    "- from sklearn.model_selection import train_test_split\n",
    "\n",
    "3 : 混合行列の描写\n",
    " - 混同行列（confusion matrix）はクラス分類問題の結果を「実際のクラス」と「予測したクラス」を軸にしてまとめたもの。\n",
    " - from sklearn.metrics import confusion_matrix \n",
    " \n",
    "4 : ループ処理を楽にするitertools \n",
    " - https://qiita.com/__cooper/items/ff1d3d71088abb5d0849\n",
    "```\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "```\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "次回Todo : まとめ（from ３セル目寄り）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20200208 1810-1830\n",
    "Generatorとは\n",
    "* RAMに乗り切らないデータを扱う時に用いる．\n",
    "* pythonの場合はyieldがこれにあたる\n",
    "* 学習用と検証用に分けるのがmodel.fit_generator, 評価用にはevaluate_generator，予測用にはpredict_generatorを使うと良い．\n",
    "* kerasではgeneratorを使わない場合，model.fit(X_train, y_train, epochs=20,      validation_split=0.2, batch_size=32)で計算可能"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
